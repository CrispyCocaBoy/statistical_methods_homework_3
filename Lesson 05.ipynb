{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning, Lab #5: SVMs\n",
    "\n",
    "[In the textbook: Section 9.6.1]\n",
    "\n",
    "Here we will use the `SVC` class from the Scikit-learn package (`sklearn`), which implements support vector classification.\n",
    "\n",
    "If you run this notebook on Google Colab, type `!pip install ISLP` in the following code cell and run it (it will take a while). Then, restart your session (Runtime menu > Restart session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt  # import subplots, cm\n",
    "import sklearn.model_selection as skm\n",
    "from ISLP import load_data, confusion_table\n",
    "import sklearn.pipeline as pipeline\n",
    "\n",
    "# lab-specific libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from ISLP.svm import plot as plot_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier\n",
    "\n",
    "The function for fitting a support vector classifier is `SVC(C, kernel, ...)`, with `kernel=\"linear\"`. **Note that** this implementation uses the dual problem, so `C` here represents the cost of a violation to the margin:\n",
    "\n",
    "* small cost -> wide margins, many support vectors on the margins;\n",
    "* large cost -> narrow margins, few support vectors on the margins.\n",
    "\n",
    "We begin by generating some random data in two classes, using two variables so that we can plot the resulting decision boundary.\n",
    "\n",
    "We plot the generated data to check whether the classes are linearly separable (they are not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "rng = np.random.default_rng(1)\n",
    "X = rng.standard_normal((50, 2))  # a data matrix\n",
    "y = np.array([-1] * 25 + [1] * 25)  # a label vector\n",
    "X[y == 1] += 1  # shifting by (1,1) all points with class 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit a **support vector classifier** with an arbitrary value of the cost `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = SVC(C=10, kernel=\"linear\")\n",
    "svm_linear.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the data together with the decision boundary by using the ISLP function `plot_svm()` with the SVC fit and the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_svm(X, y, svm_linear, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used a linear kernel, the decision boundary is linear. Crosses (`+`) indicate the support vectors and the remaining observations are plotted as circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of support vectors\n",
    "svm_linear.support_vectors_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of support vectors by class\n",
    "svm_linear.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What changes if we use a smaller cost parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_small = SVC(C=0.1, kernel=\"linear\")\n",
    "svm_linear_small.fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_svm(X, y, svm_linear_small, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of support vectors increases (wider margin). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_small.support_vectors_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_small.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the coefficients of the linear decision boundary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_small.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to compute the decision boundary line\n",
    "\n",
    "For a 2D dataset (features $x_0$, $x_1$), the equation of the decision boundary is\n",
    "\n",
    "$$w_0x_0 + w_1x_1 + b = 0$$\n",
    "\n",
    "We get $w_0$, $w_1$ from `svm_linear.coef_` and $b$ from `svm_linear.intercept_`.\n",
    "\n",
    "Rewriting the decision boundary equation in the form\n",
    "\n",
    "$$x_1 = mx_0 + c$$\n",
    "\n",
    "we then derive the slope and intercept as follows:\n",
    "\n",
    "- $m = -\\frac{w_0}{w_1}$\n",
    "- $c = -\\frac{b}{w_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = svm_linear_small.coef_[0]\n",
    "b = svm_linear_small.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -w[0] / w[1]\n",
    "c = -b / w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(min(X[:, 0]) - 0.1, max(X[:, 0]) + 0.1, 100)\n",
    "y_vals = c + m * x_vals\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "ylim = ax.get_ylim()\n",
    "ax.plot(x_vals, y_vals, color=\"k\")\n",
    "ax.set_ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "An optimal value for the `C` parameter can be found by trying different values in a cross-validation setting. \n",
    "\n",
    "In scikit-learn, cross-validation is performed with a \"splitter\" generator contained in the [model_selection](https://scikit-learn.org/stable/api/sklearn.model_selection.html) submodule. For example, K-Fold is implemented in the class `KFold(n_splits)`.\n",
    "\n",
    "Exhaustive grid search via cross-validation is performed with the `GridSearchCV(model, param_grid, cv, ...)` function, where:\n",
    "- `model` is a scikit-learn \"estimator\"\n",
    "- `param_grid` is a Python dictionary whose keys are parameter names and whose values are lists of parameter settings to try (e.g., `{'C': [1, 10, 100]}`)\n",
    "- `cv` is either a splitter object or an integer specifying the number of folds of a plain K-Fold CV. Passing a splitter object allows for more flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.001, 0.01, 0.1, 1, 5, 10, 100]\n",
    "\n",
    "kfold = skm.KFold(5, random_state=0, shuffle=True)\n",
    "grid = skm.GridSearchCV(\n",
    "    svm_linear,\n",
    "    {\"C\": C_values},\n",
    "    refit=True,\n",
    "    cv=kfold,\n",
    "    scoring=\"accuracy\",  # use accuracy as the reference metric (default)\n",
    ")\n",
    "grid.fit(X, y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation metrics for each of these models are stored in the attribute `grid.cv_results_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is quantified in terms of CV accuracy (as we specified earlier).\n",
    "We just extract the accuracy values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that  `C=1` results in the highest cross-validation accuracy of 0.74, though the accuracy is the same for several values of `C`. To extract the optimal `C` value programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model, corresponding to the optimal `C`, is also stored as the attribute `best_estimator_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmod = grid.best_estimator_\n",
    "bestmod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the `predict()` method to predict class labels using the best model.\n",
    "\n",
    "To this aim, we generate a set of test observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = rng.standard_normal((20, 2))\n",
    "y_test = np.array([-1] * 10 + [1] * 10)\n",
    "X_test[y_test == 1] += 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.coolwarm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = bestmod.predict(X_test)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our usual confusion matrix\n",
    "confusion_table(ypred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "(ypred == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, with this value of `C`, 70% of the test observations are correctly classified.  What if we had instead used `C=0.01`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mod = SVC(C=0.01, kernel=\"linear\")\n",
    "svm_mod.fit(X, y)\n",
    "\n",
    "ypred = svm_mod.predict(X_test)\n",
    "confusion_table(ypred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "(ypred == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case 60% of test observations are correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearly separable classes\n",
    "\n",
    "If we further separate the two classes in our simulated `X` matrix, they are now linearly separable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[y == 1,] += 1.9\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit a support vector classifier on these new data, with a large value for `C` in order to obtain no misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mod = SVC(C=1e5, kernel=\"linear\")\n",
    "svm_mod.fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_svm(X, y, svm_mod, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All observations are perfectly classified. Only 3 support vectors were used: that's because we used a large value of `C`, which also means that these support vectors are on the margin, and define it.\n",
    "\n",
    "_What do you think of this model? How are the margins? How do you think it will perform on unseen test data?_\n",
    "\n",
    "One may wonder how good the classifier could be on test data that depends on only three data points!\n",
    "\n",
    "The confusion matrix also shows that there are no misclassifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = svm_mod.predict(X)\n",
    "confusion_table(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit another model with a smaller `C` (say, 0.1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mod = SVC(C=0.1, kernel=\"linear\")\n",
    "svm_mod.fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_svm(X, y, svm_mod, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mod.support_vectors_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = svm_mod.predict(X)\n",
    "confusion_table(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `C=0.1`, we do not misclassify any training observations, but also obtain a much wider margin and make use of 12 support vectors. These jointly define the orientation of the decision boundary, and since there are more of them, it is more stable. It seems possible that this model will perform better on test data than the model with `C=1e5`. Let's verify by generating some test data, like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = rng.standard_normal((20, 2))\n",
    "y_test = np.array([-1] * 10 + [1] * 10)\n",
    "X_test[y_test == 1] += 1.9\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.coolwarm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = svm_mod.predict(X_test)\n",
    "confusion_table(ypred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "(ypred == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "[In the textbook: Section 9.6.2]\n",
    "\n",
    "So far we used a linear kernel Support Vector Classifier, which enabled us to deal with data having linear (or linear-like) class boundaries. But if we want to fit an SVM on data with non-linear class boundary, we need to use a non-linear kernel such as polynomial or radial. We can do this by using the same `SVC()` estimator with the appropriate choice for the `kernel` argument. Each type of kernel has its own additional arguments.\n",
    "\n",
    "* `kernel=\"radial\"`: set the value of $\\gamma$ for the radial basis kernel changing the `gamma` argument;\n",
    "* `kernel=\"poly\"`: set the polynomial degree $d$ changing the `degree` argument.\n",
    "\n",
    "We generate some data with non-linear boundary, and plot them to verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rng.standard_normal((200, 2))\n",
    "X[:100] += 2\n",
    "X[100:150] -= 2\n",
    "y = np.array([1] * 150 + [2] * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly split the observations into training and testing partitions of equal size (using scikit-learn's `train_test_split` function). Then we use the training subset to fit a radial kernel SVM with $\\gamma=1$, plotting the data and the (non-linear) decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = skm.train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = SVC(kernel=\"rbf\", gamma=1, C=1)\n",
    "svm_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_svm(X_train, y_train, svm_rbf, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, it seems like that there are some training errors. We can try to reduce them by increasing `C`. However, this comes at the price of a more irregular decision boundary that seems to be at risk of overfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = SVC(kernel=\"rbf\", gamma=1, C=1e5)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_svm(X_train, y_train, svm_rbf, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of trying \"by hand\" different values of `C`, we follow a tuning approach through cross-validation, as we did for the linear SVM. This time we need to tune also the `gamma` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = [0.1, 1, 10, 100, 1000]\n",
    "gamma_range = [0.5, 1, 2, 3, 4]\n",
    "\n",
    "params = {\"C\": C_range, \"gamma\": gamma_range}\n",
    "\n",
    "kfold = skm.KFold(5, random_state=0, shuffle=True)\n",
    "\n",
    "grid = skm.GridSearchCV(svm_rbf, param_grid=params, refit=True, cv=kfold, scoring=\"accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best choice of parameters under five-fold CV is achieved at `C=1` and `gamma=0.5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit a SVM model with the optimal values of `C` and `gamma`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm = grid.best_estimator_\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_svm(X_train, y_train, best_svm, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = best_svm.predict(X_test)\n",
    "confusion_table(y_hat_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_hat_test != y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these parameters, 12% of test\n",
    "observations are misclassified by this SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curves\n",
    "\n",
    "[In the textbook: Section 9.6.3]\n",
    "\n",
    "The ROC curves are a useful diagnostic tool for interpreting the performance of a binary classifier: they summarize in a plot the trade-off between the _true positive rate_ and the _false positive rate_ for different probability thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Here is a brief recap from Lab #1 (see also the textbook, pages 150-152).\n",
    "\n",
    "The ingredients of the ROC curve are:\n",
    "\n",
    "* *sensitivity* (or *recall*, or *true positive rate*) = TP / (TP + FN)\n",
    "* *specificity* (or *true negative rate*) = TN / (TN + FP)\n",
    "* *false positive rate* = FP / (FP + TN) = 1 - specificity\n",
    "\n",
    "where TP (true positives), TN (true negatives), FP (false positives), and FN (false negatives) are the four cells of the confusion matrix: TP and TN stay on the main diagonal; FP and FN on the antidiagonal.\n",
    "\n",
    "ROC curves are obtained by plotting the sensitivity vs. the false positive rate, which is 1 - specificity.\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling what we did in Lab #1, we would need a function for drawing a ROC curve using as inputs a vector of numerical scores for each observations (`pred`), and a vector of true labels (`truth`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting `pred` for SVMs is a little bit tricky. We know so far that SVMs output class labels of each observation, but we can also get the *fitted values*, i.e., the numerical scores representing whether a predicted sample lies to the right or left side of the hyperplane and how far from it.\n",
    "\n",
    "For a support vector classifier, the fitted value for an observation $X=(X_1,X_2, \\ldots, X_p)^T$ takes the form  $\\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\hat{\\beta}_2X_2 + \\ldots + \\hat{\\beta}_pX_p = \\hat{\\beta}_0 + \\beta^T X$. For non-linear SVMs, see equation 9.23 in the textbook. Basically, if the fitted value for a given observation is $>0$, that observation gets assigned to one class, otherwise to the other.\n",
    "\n",
    "We can access these fitted values by calling the `decision_function()` method of a fitted SVM estimator.\n",
    "\n",
    "The scikit-learn function `RocCurveDisplay.from_estimator()` (which here is abbreviated to `roc_curve()`) will produce a plot of a ROC curve. It takes a fitted estimator, followed by a data matrix and the corresponding labels.\n",
    "The argument `name` is used in the legend, while `color` is used for the color of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve = RocCurveDisplay.from_estimator  # shorthand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "roc_curve(best_svm, X_train, y_train, name=\"Training\", color=\"r\", ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compare with the ROC curve corresponding to a more flexible fit with higher $\\gamma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_flex = SVC(kernel=\"rbf\", gamma=50, C=1)\n",
    "svm_flex.fit(X_train, y_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "roc_curve(svm_flex, X_train, y_train, name=\"Training $\\gamma=50$\", color=\"r\", ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curve corresponding to the model with $\\gamma=50$ looks better.\n",
    "\n",
    "But what threshold are we changing for computing the ROC curve of a SVM? \n",
    "\n",
    "We remember that the predicted label $\\hat{y}$ is given by $\\hat{y} = sign(\\hat{\\beta}_0 + \\beta^TX)$. In equivalent terms, $\\hat{y}=0$ if $\\hat{\\beta}_0 + \\beta^TX < 0$, $\\hat{y}=1$ otherwise. \n",
    "\n",
    "We can control the positive detection rate by introducing a threshold $\\epsilon$ so that $\\hat{y}=0$ if $\\hat{\\beta}_0 + \\beta^TX < \\epsilon$, $\\hat{y}=1$ otherwise. So the ROC curve is computed by varying this $\\epsilon$.\n",
    "\n",
    "We derived ROC curves only on the training data so far! We are more interested in assessing the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "roc_curve(svm_flex, X_test, y_test, name=\"Test $\\gamma=50$\", color=\"b\", ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "roc_curve(\n",
    "    svm_flex, X_train, y_train, name=\"SVM $\\gamma=50$ on training\", ax=ax, color=\"r\"\n",
    ")\n",
    "\n",
    "roc_curve(svm_flex, X_test, y_test, name=\"SVM $\\gamma=50$ on test\", ax=ax, color=\"b\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "roc_curve(best_svm, X_train, y_train, name=\"Tuned SVM on training\", ax=ax, color=\"r\")\n",
    "\n",
    "roc_curve(best_svm, X_test, y_test, name=\"Tuned SVM on test\", ax=ax, color=\"b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compute the ROC curves on the test data, the model with $\\gamma=0.5$ appears to provide the most accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass SVM\n",
    "\n",
    "[In the textbook: Section 9.6.4]\n",
    "\n",
    "The `SVC()` function will perform automatically multi-class classification when the response variable contains more than 2 levels. The approach for multi-class classification can be either the **one-versus-one** approach (when `decision_function_shape=='ovo'`) or **one-versus-rest**, also known as one-versus-all (when `decision_function_shape=='ovr'`). Note that one-versus-rest is the default choice in `SVC()`.\n",
    "\n",
    "We see an example on synthetic 3-class data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(123)\n",
    "X = np.vstack([X, rng.standard_normal((50, 2))])\n",
    "y = np.hstack([y, [0] * 50])\n",
    "X[y == 0, 1] += 2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit an SVM to the data, picking the \"one-versus-one\" approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_3 = SVC(kernel=\"rbf\", C=10, gamma=1, decision_function_shape=\"ovo\")\n",
    "svm_rbf_3.fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_svm(X, y, svm_rbf_3, scatter_cmap=plt.cm.tab10, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to Gene Expression Data\n",
    "\n",
    "Let's switch to a real-world data set. We use the `Khan` data, consisting of gene expression measurements for a number of tissue samples (observations) corresponding to four types of small round blue cell tumors. The observations and labels are already partitioned into a training set (`xtrain`, `ytrain`) and a testing set (`xtest`, `ytest`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Khan = load_data(\"Khan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get a grasp on the data by looking at the variable names and the dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Khan[\"xtrain\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Khan[\"xtrain\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Khan[\"xtest\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the label stratification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Khan[\"ytrain\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Khan[\"ytrain\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a support vector approach to predict cancer subtype using gene expression measurements.  In this data set, there is a very large number of features relative to the number of observations. This\n",
    "suggests that we should use a linear kernel, because the additional flexibility that will result from using a polynomial or radial kernel is unnecessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khan_linear = SVC(kernel=\"linear\", C=10)\n",
    "khan_linear.fit(Khan[\"xtrain\"], Khan[\"ytrain\"])\n",
    "\n",
    "ypred_tr = khan_linear.predict(Khan[\"xtrain\"])\n",
    "confusion_table(ypred_tr, Khan[\"ytrain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right: there are _no_ training errors! This is related to the \"features $\\gg$ observations\" situation: it is easier to find a hyperplane that fully separates the classes.\n",
    "\n",
    "We now wonder how well this model performs on the testing data: let's find out. _Remember that nothing can be said on the performance and generalization ability of a model until you evaluate it on unseen data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_ts = khan_linear.predict(Khan[\"xtest\"])\n",
    "confusion_table(ypred_ts, Khan[\"ytest\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was not so bad: only two test errors!\n",
    "\n",
    "_Further improvements_: this performance comes from a single training/testing partition. In order to get more precise performance estimates, one could repeat the procedure on different partitions, for example using a $k$-fold Cross-Validation approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
